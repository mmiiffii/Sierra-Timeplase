name: Tidy Images (flatten + rename new + weekly folders)

on:
  workflow_dispatch: {}
  # schedule:
  #   - cron: "15 * * * *"  # example: every hour at :15 (UTC)

permissions:
  contents: write

jobs:
  tidy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Tidy images
        id: tidy
        run: |
          python3 - <<'PYCODE'
          import os, re, csv, json, time, shutil, subprocess
          from pathlib import Path
          from datetime import datetime, timedelta

          ROOT = Path(".").resolve()
          IMAGES = ROOT / "images"
          MAINT = ROOT / ".maintenance"
          AUDITS = IMAGES  # place audit files in /images
          IMAGES.mkdir(parents=True, exist_ok=True)
          MAINT.mkdir(parents=True, exist_ok=True)

          STATE_FILE = MAINT / "images_state.json"
          EXTS = {".jpg",".jpeg",".png",".gif",".webp",".tif",".tiff",".bmp"}
          NOW = datetime.utcnow()

          # ---------- helpers ----------
          def git_mv(src: Path, dst: Path):
            try:
              subprocess.run(["git","mv","-k",str(src),str(dst)], check=True,
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)
              return True
            except Exception:
              return False

          def move_file(src: Path, dst: Path):
            dst.parent.mkdir(parents=True, exist_ok=True)
            if not git_mv(src, dst):
              shutil.move(str(src), str(dst))

          def list_images_anywhere():
            return [p for p in ROOT.rglob("*")
                    if p.is_file() and p.suffix.lower() in EXTS and ".git" not in p.parts]

          def is_under_images_any(p: Path):  # /images prefix
            try: p.relative_to(IMAGES); return True
            except ValueError: return False

          def is_under_images_root(p: Path): # exactly /images/*
            return p.parent == IMAGES

          # extract timestamp; accept YYYYMMDD_HHMMSS or YYMMDD_HHMMSS anywhere
          PAT_8 = re.compile(r"(\d{8}_\d{6})")
          PAT_6 = re.compile(r"(\d{6}_\d{6})")
          def extract_ts_from_name(name: str):
            m = PAT_8.search(name)
            if m:
              date8, time6 = m.group(1).split("_")
              yy = date8[2:4]; mm = date8[4:6]; dd = date8[6:8]
              return f"{yy}{mm}{dd}_{time6}"
            m = PAT_6.search(name)
            if m:
              return m.group(1)  # already YYMMDD_HHMMSS
            return None

          def ts_to_datetime(tsYY: str):
            # tsYY = YYMMDD_HHMMSS -> assume 2000-2099
            YY,MM,DD = tsYY[:2], tsYY[2:4], tsYY[4:6]
            hh,mm,ss = tsYY[7:9], tsYY[9:11], tsYY[11:13]
            year = 2000 + int(YY)
            return datetime(year, int(MM), int(DD), int(hh), int(mm), int(ss))

          def week_bucket_for(ts: datetime):
            # Monday-start week number (%W has Monday as first day on many systems, but 00 for days before first Monday)
            # We'll compute ISO week, but labeling by "Week XX - range"
            # Range: Monday..Sunday of that ISO week
            iso_year, iso_week, iso_weekday = ts.isocalendar()  # Monday=1..Sunday=7
            # find Monday of this week
            monday = ts - timedelta(days=iso_weekday-1)
            monday = datetime(monday.year, monday.month, monday.day)
            sunday = monday + timedelta(days=6)
            # Label format:
            def d_label(d: datetime):
              month_abbr = d.strftime("%b")  # Jan, Feb, ...
              return f"{d.day:02d}{month_abbr}"
            # If month same:
            if monday.month == sunday.month:
              range_label = f"{monday.day:02d}-{sunday.day:02d}{monday.strftime('%b')}"
            else:
              range_label = f"{d_label(monday)}-{d_label(sunday)}"
            folder = f"Week {iso_week:02d} - {range_label}"
            return folder

          # ---------- load state ----------
          last_run_iso = None
          if STATE_FILE.exists():
            try:
              state = json.loads(STATE_FILE.read_text(encoding="utf-8"))
              last_run_iso = state.get("last_run_utc")
            except Exception:
              last_run_iso = None
          last_run_dt = datetime.fromisoformat(last_run_iso) if last_run_iso else None

          # ---------- audits ----------
          TS = time.strftime("%Y%m%d_%H%M%S")
          audit_txt = AUDITS / f"tidy_audit_{TS}.txt"
          audit_csv = AUDITS / f"tidy_audit_{TS}.csv"

          flattened = []
          renamed = []
          organized = []
          skipped_no_ts = []
          unchanged = []

          # ---------- 1) FLATTEN ----------
          all_before = list_images_anywhere()
          outside = [p for p in all_before if not is_under_images_any(p)]
          nested = [p for p in all_before if is_under_images_any(p) and not is_under_images_root(p)]
          candidates_flatten = sorted(set(outside + nested))
          # collision-safe dest in /images
          def dest_in_images(src: Path):
            cand = IMAGES / src.name
            if not cand.exists(): return cand
            base, ext = src.stem, src.suffix.lower()
            parent = src.parent.name or "root"
            i = 1
            while (IMAGES / f"{base}_from_{parent}_{i}{ext}").exists():
              i += 1
            return IMAGES / f"{base}_from_{parent}_{i}{ext}"

          for src in candidates_flatten:
            if not src.exists():  # moved by earlier item
              continue
            if src.parent == IMAGES:
              continue
            dst = dest_in_images(src)
            move_file(src, dst)
            flattened.append((src, dst))

          # After flatten, list files directly in /images (images only)
          direct_files = [p for p in IMAGES.iterdir() if p.is_file() and p.suffix.lower() in EXTS]

          # ---------- 2) RENAME (only new since last run) ----------
          # Criteria to rename:
          #   - files in /images root (we create week folders in step 3)
          #   - with a timestamp we can parse
          #   - If last_run_dt is set, only process those whose ts > last_run_dt
          for p in sorted(direct_files):
            tsYY = extract_ts_from_name(p.name)
            if not tsYY:
              unchanged.append(p.name)
              continue
            ts_dt = None
            try:
              ts_dt = ts_to_datetime(tsYY)
            except Exception:
              unchanged.append(p.name)
              continue
            if last_run_dt and ts_dt <= last_run_dt:
              unchanged.append(p.name)
              continue
            new_name = f"image_{tsYY}{p.suffix.lower()}"
            if p.name == new_name:
              unchanged.append(p.name)
              continue
            dest = p.with_name(new_name)
            # collision-safe
            if dest.exists():
              i = 1
              while True:
                cand = p.with_name(f"image_{tsYY}_{i}{p.suffix.lower()}")
                if not cand.exists():
                  dest = cand; break
                i += 1
            move_file(p, dest)
            renamed.append((p.name, dest.name))

          # Refresh direct files after rename
          direct_files = [p for p in IMAGES.iterdir() if p.is_file() and p.suffix.lower() in EXTS]

          # ---------- 3) ORGANIZE INTO WEEKLY FOLDERS (only new since last run) ----------
          # Move renamed files (and any with ts > last_run) into weekly subfolders.
          for p in sorted(direct_files):
            tsYY = extract_ts_from_name(p.name)
            if not tsYY:
              skipped_no_ts.append(p.name)
              continue
            try:
              ts_dt = ts_to_datetime(tsYY)
            except Exception:
              skipped_no_ts.append(p.name)
              continue
            if last_run_dt and ts_dt <= last_run_dt:
              continue
            week_folder = week_bucket_for(ts_dt)
            dst = IMAGES / week_folder / p.name
            if dst.exists():
              i = 1
              base, ext = p.stem, p.suffix.lower()
              while (p.parent / week_folder / f"{base}_{i}{ext}").exists():
                i += 1
              dst = IMAGES / week_folder / f"{base}_{i}{ext}"
            move_file(p, dst)
            organized.append((p.name, str(dst.relative_to(IMAGES))))

          # ---------- write audits ----------
          lines = []
          lines.append(f"TIDY AUDIT (UTC {NOW.strftime('%Y-%m-%d %H:%M:%S')})")
          lines.append(f"Last run (UTC): {last_run_dt.isoformat() if last_run_dt else '(first run)'}")
          lines.append("")
          lines.append("== Flatten ==")
          lines.append(f"Moved into /images: {len(flattened)}")
          for s,d in flattened[:1000]:
            lines.append(f"{s} -> {d}")
          lines.append("")
          lines.append("== Rename (new since last run) ==")
          lines.append(f"Renamed: {len(renamed)}")
          for o,n in renamed[:1000]:
            lines.append(f"{o} -> {n}")
          lines.append("")
          lines.append("== Organize into weekly folders (new since last run) ==")
          lines.append(f"Organized: {len(organized)}")
          for o,d in organized[:1000]:
            lines.append(f"{o} -> {d}")
          lines.append("")
          lines.append(f"Unchanged (skipped or already correct): {len(unchanged)}")
          lines.extend([u for u in unchanged[:1000]] or ["(none)"])
          lines.append("")
          lines.append(f"Skipped (no parsable timestamp): {len(skipped_no_ts)}")
          lines.extend([s for s in skipped_no_ts[:1000]] or ["(none)"])
          lines.append("")
          audit_txt.write_text("\n".join(lines), encoding="utf-8")

          with open(audit_csv, "w", newline="", encoding="utf-8") as fcsv:
            w = csv.writer(fcsv)
            w.writerow(["phase","source","destination_or_note"])
            for s,d in flattened:
              w.writerow(["flatten", str(s), str(d)])
            for o,n in renamed:
              w.writerow(["rename", o, n])
            for o,d in organized:
              w.writerow(["organize", o, d])
            for u in unchanged:
              w.writerow(["unchanged", u, ""])
            for s in skipped_no_ts:
              w.writerow(["skipped_no_ts", s, ""])

          print(f"📝 Audit TXT: {audit_txt}")
          print(f"🗂️  Audit CSV: {audit_csv}")

          # ---------- update state ----------
          new_state = {"last_run_utc": NOW.isoformat(timespec="seconds")}
          STATE_FILE.write_text(json.dumps(new_state, indent=2), encoding="utf-8")
          print(f"🗃️  Updated state: {STATE_FILE}")

          # Outputs for summary
          with open("tidy_counts.json","w") as jf:
            json.dump({
              "flattened": len(flattened),
              "renamed": len(renamed),
              "organized": len(organized),
              "skipped_no_ts": len(skipped_no_ts),
              "unchanged": len(unchanged),
              "state_file": str(STATE_FILE)
            }, jf)
          PYCODE

      - name: Commit and push changes
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add images/ .maintenance/
          git commit -m "Tidy images: flatten + rename new + weekly organize" || echo "No changes"
          git push

      - name: Summary
        run: |
          python3 - <<'PYCODE'
          import json, glob
          data = json.load(open("tidy_counts.json"))
          print("## Tidy Images Summary")
          print(f"- Flattened (moved into /images): {data['flattened']}")
          print(f"- Renamed (new since last run): {data['renamed']}")
          print(f"- Organized into weekly folders: {data['organized']}")
          print(f"- Skipped (no timestamp): {data['skipped_no_ts']}")
          print(f"- Unchanged: {data['unchanged']}")
          print("")
          print(f"State file: {data['state_file']}")
          print("Audit files: see /images/tidy_audit_*.txt and .csv")
          PYCODE | tee -a $GITHUB_STEP_SUMMARY
